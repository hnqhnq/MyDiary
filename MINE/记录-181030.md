## 文本初步预处理流程

#### 1. 分句

- 实现库：pyltp.SentenceSplitter.split

#### 2. 分词

- 实现库：jieba.cut、pyltp.Segmentor.segment (哈工大，加载模型)、hanlp、stanfordnlp

- 依赖语料：业务领域的外部分词词典，可使用通用版后根据业务专业名词做相应调整优化

- 优化：


  - 分词不准确：

  ​	① 加载外部字典 

  ​	② 设定正则规则匹配替换

  - 加载字典冲突：

  ​	① 调整词频和字典顺序



#### 3. 词性标注

- 实现库：pyltp.Postagger(需要加载模型)、jieba.posseg(不需加载模型)、hanlp、stanfordnlp


```
postags = ['nh', 'r', 'r', 'v']
postags = [pair('我', 'r'), pair('是', 'v'), pair('中华人民共和国', 'ns'), pair('的', 'uj'), pair('未来', 't')]
```

#### 4. 停用词

- 依赖语料：没有语义的符号以及单字（如：。、的……）通用版即可，后期通过业务需求做调整优化。

#### 5. 去除干扰词

- 去除不需要的词性(如：只保留名词.startswith('n'))

#### 6.命名实体识别

- 实现库：pyltp.NamedEntityRecognizer(需要加载模型)、hanlp、stanfordnlp

```
netags = ['O', 'O', 'O', 'B-Nh', 'I-Nh', 'I-Nh', 'I-Nh',……]
```

#### 7.依存句法分析

- 实现库：pyltp.Parser(加载模型)、hanlp、stanfordnlp

```
2:SBV  0:HED  4:ATT  5:SBV  2:VOB
主谓关系 核心关系  定中关系 主谓关系 动宾关系
```

#### 8.角色标注

- 实现库：pyltp.SementicRoleLabeller(需要加载模型)
- 暂未出结果……

[^源码参见]: hagongda.py、do_namedentity.py




## 主题提取

#### 1. 关键词提取

- TF-IDF模型【依赖文档库】

- textrank模型【pagerange原理，不需要依赖文档库】

- 主题模型：【使用gensim的接口，将文本转为向量化表示，构建词向量空间。依赖文档库】

  - LSI模型 
  - LDA模型

  ​

#### 2. 命名实体识别

- 相关实现库：pyltp、crfpp、hanlp、stanfordnlp
- 时间、人名、地名、机构名（机构名效果有待提升）


[^源码参见]: KeywordExtract.py、do_namedentity.py



#### 自定义语法与CFG

**什么是语法解析？**

- 在自然语言学习过程中，每个人一定都学过语法，例如句子可以用主语、谓语、宾语来表示。在自然语言的处理过程中，有许多应用场景都需要考虑句子的语法，因此研究语法解析变得非常重要。
- 语法解析有两个主要的问题，其一是句子语法在计算机中的表达不存储方法，以及语料数据集；其二是语法解析的算法。
- 对于第一个问题，我们可以用树状结构图来表示，如下图所示，S表示句子；NP、VP、PP是名词、动词、介词短语（短语级别）；N、V、P分别是名词、动词、介词。



**什么是语法解析？**

![54089168747](D:\Diary\temp\1540891687477.png)





**上下文无关语法（Context-Free Grammer）**

为了生成句子的语法树，我们可以定义如下的一套上下文无关语法：
	•1）N表示一组非叶子节点的标注，例如{S、NP、VP、N...}
	•2）Σ表示一组叶子结点的标注，例如{boeing、is...}
	•3）R表示一组觃则，每条觃则可以表示为

![54089196382](D:\Diary\temp\1540891963825.png)

​	•4）S表示语法树开始的标注
	•举栗子来说，语法的一个语法子集可以表示为下图所示。当给定一个句子时，我们便可以按照		  从左到右的顺序来解析语法。例如，句子the man sleeps就可以表示为(S (NP (DT the) (NN man)) (VP sleeps))。



**上下文无关语法（Context-Free Grammer）**

![54089225902](D:\Diary\temp\1540892259028.png)










